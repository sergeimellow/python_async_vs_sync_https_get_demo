import aiohttp
import asyncio
import os
import time
import base64
import csv
import argparse
from urllib.request import urlopen


sync_requests_path = 'sync-requests/'
async_requests_path = 'async-requests/'

"""
============================= HELPER METHODS =============================

These methods are primarily to setup before making any requests

"""

# creates "sync-requests/" and "async-requests/"" within the current directory
def make_async_and_sync_directories():
    sync_dir_exists = os.path.exists(sync_requests_path)
    if not sync_dir_exists:
        os.makedirs(sync_requests_path)
        print("The " + sync_requests_path + " directory was created!")

    async_dir_exists = os.path.exists(async_requests_path)
    if not async_dir_exists:
        os.makedirs(async_requests_path)
        print("The " + async_requests_path + " directory was created!")

# used to make safe unique string from a url
def url_to_filename(url):
    url = url.encode('UTF-8')
    return base64.urlsafe_b64encode(url).decode('UTF-8')  

# reverse safe unique string generated by url_to_filename() back into a url
def filename_to_url(url):
    return base64.urlsafe_b64decode(url).decode('UTF-8')


# reads the first column of a csv into a tuple
def urls_csv_to_tuples(csv_file_name):
    with open(csv_file_name, newline='') as f:
        reader = csv.reader(f)
        urls = [row[0] for row in reader]
    
    return urls

# creates a parser and parses all args (just a csv file for now)
def get_command_line_args():
    parser = argparse.ArgumentParser(description='make some requests.')
    parser.add_argument('csv', type=str, help='path to 1 column csv with list of URLs to download')
    return parser.parse_args()


"""
============================= MAIN METHODS =============================

These methods are used to perform async vs sync python https get requests

"""


# runs a bunch of asynchronous get requests and prints status code of each result at the end
async def make_async_requests(urls):
    async with aiohttp.ClientSession() as session:
        tasks = []
        for url in urls:
            tasks.append(asyncio.ensure_future(get_html_and_save_response_to_file(session, url)))

        url_by_status_code = await asyncio.gather(*tasks)
        print("\n")
        print(url_by_status_code)



# makes a get request and saves html response to file named async-requests/{EPOCH_TIME}_{base64encodedURL}
async def get_html_and_save_response_to_file(session, url):
    async with session.get(url) as resp:
        code = resp.status
        html = await resp.text()
        epoch_time = time.time()
        file_name = str(epoch_time) + "_" + url_to_filename(url)
        f = open(async_requests_path + file_name, "a")
        f.write(file_name)
        f.close()
        print("get " + url + " request response saved in " + async_requests_path + file_name)
        return {url: code}


# similiar to get_html_and_save_response_to_file but uses urlopen and no async.
# The files are saved to a "sync-request/" directory with the same file name format.
def make_sync_requests(urls):
    for url in urls:
        response = urlopen(url)
        response_bytes = response.read()
        response_str = response_bytes.decode("utf-8", "ignore")
        response.close()
        epoch_time = time.time()
        file_name = str(epoch_time) + "_" + url_to_filename(url)
        f = open(sync_requests_path + file_name, "a")
        f.write(response_str)
        f.close()
        print("get " + url + " request response saved in " + sync_requests_path + file_name)

"""

compares making N https get requests synchronously vs asynchronously and saving html reponses in files for both.

Example run:
$ python3 make_async_requests.py 10_urls.csv

make_async_requests.py takes in one argument that is expected to be a path to a csv file. The code only reads
the first column of the csv file and stores it in a tuple. This tuple is expected to contain all the URLs
that are being used for the test. This tuple is used for making both the sync and async get requests. Responses
for both the sync and async requests are stored in sync-request/ and async-request/ directories respectively.

"""
if __name__ == '__main__':
    # setup via HELPER methods
    make_async_and_sync_directories()
    args = get_command_line_args()
    urls = urls_csv_to_tuples(args.csv)

    # sync requests speed test
    print("making synchronous requests...")
    start_time = time.time()
    make_sync_requests(urls)
    end_time = time.time()
    total_runtime_seconds = end_time - start_time
    print ("For {0} sync requests it took {1} ".format(len(urls), total_runtime_seconds))
    print("\n")


    # async requests speed test
    print("making asynchronous requests...")
    start_time = time.time()
    asyncio.run(make_async_requests(urls))
    end_time = time.time()
    total_runtime_seconds = end_time - start_time
    print ("For {0} async requests it took {1} ".format(len(urls), total_runtime_seconds))

    
    """
    example results:

    $ python3 make_async_requests.py 10_urls.csv
    The sync-requests/ directory was created!
    The async-requests/ directory was created!
    making synchronous requests...
    get https://www.google.com request response saved in sync-requests/1657132366.811193_aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbQ==
    get https://www.plus.google.com request response saved in sync-requests/1657132367.961231_aHR0cHM6Ly93d3cucGx1cy5nb29nbGUuY29t
    get https://www.youtube.com request response saved in sync-requests/1657132368.5839438_aHR0cHM6Ly93d3cueW91dHViZS5jb20=
    get https://www.facebook.com request response saved in sync-requests/1657132368.800961_aHR0cHM6Ly93d3cuZmFjZWJvb2suY29t
    get https://www.instagram.com request response saved in sync-requests/1657132369.4767401_aHR0cHM6Ly93d3cuaW5zdGFncmFtLmNvbQ==
    get https://www.twitter.com request response saved in sync-requests/1657132370.003985_aHR0cHM6Ly93d3cudHdpdHRlci5jb20=
    get https://www.gmail.com request response saved in sync-requests/1657132371.953959_aHR0cHM6Ly93d3cuZ21haWwuY29t
    get https://www.ebay.com request response saved in sync-requests/1657132372.6347709_aHR0cHM6Ly93d3cuZWJheS5jb20=
    get https://www.linkedin.com request response saved in sync-requests/1657132372.983913_aHR0cHM6Ly93d3cubGlua2VkaW4uY29t
    get https://www.apple.com request response saved in sync-requests/1657132373.471808_aHR0cHM6Ly93d3cuYXBwbGUuY29t
    For 10 sync requests it took 7.031887769699097


    making asynchronous requests...
    get https://www.apple.com request response saved in async-requests/1657132373.614781_aHR0cHM6Ly93d3cuYXBwbGUuY29t
    get https://www.facebook.com request response saved in async-requests/1657132373.652744_aHR0cHM6Ly93d3cuZmFjZWJvb2suY29t
    get https://www.instagram.com request response saved in async-requests/1657132373.694653_aHR0cHM6Ly93d3cuaW5zdGFncmFtLmNvbQ==
    get https://www.linkedin.com request response saved in async-requests/1657132373.759725_aHR0cHM6Ly93d3cubGlua2VkaW4uY29t
    get https://www.google.com request response saved in async-requests/1657132373.8172119_aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbQ==
    get https://www.youtube.com request response saved in async-requests/1657132373.9874618_aHR0cHM6Ly93d3cueW91dHViZS5jb20=
    get https://www.ebay.com request response saved in async-requests/1657132374.1642072_aHR0cHM6Ly93d3cuZWJheS5jb20=
    get https://www.twitter.com request response saved in async-requests/1657132374.2042198_aHR0cHM6Ly93d3cudHdpdHRlci5jb20=
    get https://www.plus.google.com request response saved in async-requests/1657132374.493839_aHR0cHM6Ly93d3cucGx1cy5nb29nbGUuY29t
    get https://www.gmail.com request response saved in async-requests/1657132374.98636_aHR0cHM6Ly93d3cuZ21haWwuY29t


    [{'https://www.google.com': 200}, {'https://www.plus.google.com': 200}, {'https://www.youtube.com': 200}, {'https://www.facebook.com': 200}, {'https://www.instagram.com': 200}, {'https://www.twitter.com': 200}, {'https://www.gmail.com': 200}, {'https://www.ebay.com': 200}, {'https://www.linkedin.com': 200}, {'https://www.apple.com': 200}]
    For 10 async requests it took 1.5158741474151611

    The take away:

    This means for 10 requests it was 4.639 times faster. With the 10 sync requests taking 7.032 seconds and the async requests
    taking 1.516 seconds. This should be re-run with a much larger set of URLs to get a better estimate of exactly how much faster
    async is vs sync get requests.

    """
